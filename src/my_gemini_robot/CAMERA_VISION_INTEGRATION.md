# ì¹´ë©”ë¼ ë¹„ì „ í†µí•© ê°€ì´ë“œ

## ğŸ“¸ **í˜„ì¬ ìƒíƒœ**

### âœ… ì´ë¯¸ êµ¬í˜„ë¨:
1. **GeminiVisionNode** - ì¹´ë©”ë¼ ì´ë¯¸ì§€ ìˆ˜ì‹ 
2. **vision_digest** í† í”½ - ë¹„ì „ ì •ë³´ ì „ë‹¬
3. **Observation.seen** - ë³´ì¸ ê°ì²´ ì¶”ì 

### âŒ ë¯¸êµ¬í˜„:
1. **ì‹¤ì œ ì´ë¯¸ì§€ ë¶„ì„** - í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„°ë§Œ ë°˜í™˜
2. **Gemini Vision API** - ì´ë¯¸ì§€ë¥¼ Geminiì—ê²Œ ì „ë‹¬í•˜ì—¬ ë¶„ì„
3. **ëª©í‘œ ê¸°ë°˜ ê°ì²´ íƒì§€** - "ìš°ì²´í†µ", "ë¬¸" ë“± íƒì§€

## ğŸ¯ **ê°œì„  ë°©ì•ˆ**

### ë°©ë²• 1: Gemini Vision API í†µí•© (ê¶Œì¥)

Gemini 2.0ì€ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
def plan_robot_action_with_vision(
    self,
    goal: str,
    observation: Dict[str, Any],
    image_data: Optional[bytes] = None,  # â† ì´ë¯¸ì§€ ì¶”ê°€
    constraints: Dict[str, Any] = {},
    available_actions: List[str] = []
) -> Dict[str, Any]:
    """
    ì´ë¯¸ì§€ì™€ ì„¼ì„œ ë°ì´í„°ë¥¼ í•¨ê»˜ ë¶„ì„í•˜ì—¬ í–‰ë™ ê³„íš
    """
    contents = []
    
    # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
    prompt = f"""
    Goal: {goal}
    
    Current sensor data:
    - Front: {observation.get('front_range')}m
    - Left: {observation.get('left_range')}m  
    - Right: {observation.get('right_range')}m
    
    **ANALYZE THE CAMERA IMAGE BELOW:**
    - What objects do you see?
    - Is there a door? mailbox? person?
    - Which direction should I move to reach the goal?
    
    Choose ONE action based on both sensor data AND visual information.
    """
    contents.append(prompt)
    
    # ì´ë¯¸ì§€ ì¶”ê°€
    if image_data:
        contents.append({
            "mime_type": "image/jpeg",
            "data": image_data  # base64 ë˜ëŠ” bytes
        })
    
    response = self.client.models.generate_content(
        model=self.config.model_id,
        contents=contents,
        config=types.GenerateContentConfig(
            temperature=self.config.temperature,
            thinking_config=types.ThinkingConfig(
                thinking_budget=self.config.thinking_budget,
                include_thoughts=True
            ),
            tools=[types.Tool(function_declarations=function_declarations)]
        )
    )
    
    return self._parse_response(response)
```

### ë°©ë²• 2: ì£¼ê¸°ì  ë¹„ì „ ì²´í¬ (íš¨ìœ¨ì )

ë§¤ ìŠ¤í…ë§ˆë‹¤ ì´ë¯¸ì§€ ë¶„ì„ì€ ë¹„ìš©ì´ í½ë‹ˆë‹¤. ëŒ€ì‹ :

```python
# íŠ¹ì • ì¡°ê±´ì—ì„œë§Œ ë¹„ì „ í™œì„±í™”
if self.step_count % 5 == 0:  # 5ìŠ¤í…ë§ˆë‹¤
    vision_analysis = self.gemini_client.analyze_image(
        self.last_image,
        query="What objects do you see? Any doors or mailboxes?"
    )
    self.vision_digest.update(vision_analysis)
```

### ë°©ë²• 3: ê°ì²´ íƒì§€ íŒŒì´í”„ë¼ì¸ (ìµœì )

1. **ë¹ ë¥¸ ê°ì²´ íƒì§€ ëª¨ë¸** (YOLO, MobileNet) - ë¡œì»¬ ì‹¤í–‰
2. **íƒì§€ëœ ê°ì²´ë¥¼ Geminiì—ê²Œ ì „ë‹¬** - "door detected at (x,y)"
3. **Geminiê°€ ì „ëµ ìˆ˜ë¦½** - "move towards the door"

## ğŸ”§ **êµ¬í˜„ ë‹¨ê³„**

### Step 1: ì´ë¯¸ì§€ ë°ì´í„° ìˆ˜ì§‘

```python
# gemini_bridge.py - GeminiAgentNode

from cv_bridge import CvBridge
import cv2
import base64

class GeminiAgentNode(Node):
    def __init__(self):
        # ...
        self.bridge = CvBridge()
        self.last_image: Optional[Image] = None
        self.image_sub = self.create_subscription(
            Image, '/camera/image_raw', self.on_image, qos_best_effort
        )
    
    def on_image(self, msg: Image):
        """ì¹´ë©”ë¼ ì´ë¯¸ì§€ ì €ì¥"""
        self.last_image = msg
    
    def get_image_bytes(self) -> Optional[bytes]:
        """ì´ë¯¸ì§€ë¥¼ JPEG bytesë¡œ ë³€í™˜"""
        if self.last_image is None:
            return None
        
        try:
            # ROS Image â†’ OpenCV
            cv_image = self.bridge.imgmsg_to_cv2(self.last_image, 'bgr8')
            
            # OpenCV â†’ JPEG bytes
            _, buffer = cv2.imencode('.jpg', cv_image)
            return buffer.tobytes()
        except Exception as e:
            self.get_logger().error(f'ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}')
            return None
```

### Step 2: Geminiì—ê²Œ ì´ë¯¸ì§€ ì „ë‹¬

```python
# agent_loop()ì—ì„œ
obs = self.build_observation()
image_bytes = self.get_image_bytes()

action = self.gemini_client.plan_robot_action_with_vision(
    goal=self.current_task.get("task", ""),
    observation=obs.to_json(),
    image_data=image_bytes,  # â† ì´ë¯¸ì§€ ì¶”ê°€
    constraints=self.current_task.get("constraints", {})
)
```

### Step 3: ë¹„ìš© ìµœì í™”

```python
# ì´ë¯¸ì§€ ë¶„ì„ì€ 5ìŠ¤í…ë§ˆë‹¤ ë˜ëŠ” í•„ìš”ì‹œì—ë§Œ
use_vision = (
    self.step_count % 5 == 0 or  # ì£¼ê¸°ì 
    "ì°¾" in self.current_task.get("task", "") or  # íƒìƒ‰ íƒœìŠ¤í¬
    self.last_action_result.startswith("rotate")  # íšŒì „ í›„
)

if use_vision:
    image_bytes = self.get_image_bytes()
else:
    image_bytes = None
```

## ğŸ“Š **ì˜ˆìƒ íš¨ê³¼**

### Before (ì„¼ì„œë§Œ):
```
[agent] ì „ë°© 2.5m, ì¢Œ 1.8m, ìš° 3.2m
â†’ ì „ì§„ (ëª©í‘œ ë°©í–¥ ëª¨ë¦„)
```

### After (ë¹„ì „ í†µí•©):
```
[agent] ì „ë°© 2.5m, ì¢Œ 1.8m, ìš° 3.2m
[vision] ğŸ¥ ì™¼ìª½ì— ìš°ì²´í†µ ë°œê²¬, ì •ë©´ì— ë¬¸ ë³´ì„
â†’ ì™¼ìª½ íšŒì „ í›„ ì „ì§„ (ìš°ì²´í†µ í–¥í•´)
```

## âš ï¸ **ì£¼ì˜ì‚¬í•­**

1. **API ë¹„ìš©**: ì´ë¯¸ì§€ ë¶„ì„ì€ í…ìŠ¤íŠ¸ë³´ë‹¤ ë¹„ìŒˆ
   - í•´ê²°: ì£¼ê¸°ì  ë¶„ì„ (5-10ìŠ¤í…ë§ˆë‹¤)
   - í•´ê²°: ì´ë¯¸ì§€ í•´ìƒë„ ì¶•ì†Œ (640x480 ì´í•˜)

2. **ë ˆì´í„´ì‹œ**: ì´ë¯¸ì§€ ì „ì†¡ + ë¶„ì„ ì‹œê°„
   - í•´ê²°: ë¹„ë™ê¸° ë¶„ì„
   - í•´ê²°: ë¡œì»¬ ê°ì²´ íƒì§€ + Gemini ì „ëµ ìˆ˜ë¦½

3. **ë„¤íŠ¸ì›Œí¬**: ì´ë¯¸ì§€ í¬ê¸°
   - í•´ê²°: JPEG ì••ì¶• (quality=50-70)
   - í•´ê²°: ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ

## ğŸš€ **ë¹ ë¥¸ í…ŒìŠ¤íŠ¸**

```python
# gemini_api.pyì— ì¶”ê°€
def analyze_scene(self, image_bytes: bytes, query: str) -> str:
    """
    ì´ë¯¸ì§€ ì¥ë©´ ë¶„ì„
    
    Args:
        image_bytes: JPEG ì´ë¯¸ì§€ ë°ì´í„°
        query: ì§ˆë¬¸ ("What do you see?")
    
    Returns:
        ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
    """
    if not self.is_available():
        return "Vision not available"
    
    try:
        import base64
        image_b64 = base64.b64encode(image_bytes).decode('utf-8')
        
        response = self.client.models.generate_content(
            model=self.config.model_id,
            contents=[
                query,
                {
                    "mime_type": "image/jpeg",
                    "data": image_b64
                }
            ]
        )
        
        return response.text
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return f"Error: {e}"
```

## ğŸ“ **ë‹¤ìŒ ë‹¨ê³„**

ì›í•˜ì‹œëŠ” ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:

1. **Full Vision Integration** - ë§¤ ìŠ¤í…ë§ˆë‹¤ ì´ë¯¸ì§€ ë¶„ì„ (ë¹„ìš© ë†’ìŒ, ì •í™•ë„ ìµœê³ )
2. **Periodic Vision** - 5-10ìŠ¤í…ë§ˆë‹¤ ì´ë¯¸ì§€ ë¶„ì„ (ë¹„ìš© ì¤‘ê°„, íš¨ìœ¨ì )
3. **On-Demand Vision** - íŠ¹ì • íƒœìŠ¤í¬/ìƒí™©ì—ì„œë§Œ (ë¹„ìš© ë‚®ìŒ, ì„ íƒì )
4. **Hybrid** - ë¡œì»¬ ê°ì²´ íƒì§€ + Gemini ì „ëµ (ë¹„ìš© ìµœì†Œ, ìµœì )

ì–´ë–¤ ë°©ë²•ì„ êµ¬í˜„í• ê¹Œìš”?

